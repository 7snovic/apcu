APC Quick-Start Braindump

This is a rapidly written braindump of how APC currently works in the
form of a quick-start guide to start hacking on APC.

1. Install and use APC a bit so you know what it does from the end-user's
   perspective.  
   user-space functions are all explained here: 

2. Grab the current APC code from CVS:
    
    cvs -d:pserver:cvsread@cvs.php.net:/repository login
    Password: phpfi
    cvs -d:pserver:cvsread@cvs.php.net:/repository co pecl/apc

   apc/php_apc.c has most of the code for the user-visible stuff.  It is
   also a regular PHP extension in the sense that there are MINIT, MINFO, 
   MSHUTDOWN, RSHUTDOWN, etc. functions.  

3. Build it.

   cd pecl/apc
   phpize
   ./configure --enable-apcu
   make
   cp modules/apcu.so /usr/local/lib/php
   apachectl restart

4. Debugging Hints

     apachectl stop
     gdb /usr/bin/httpd
     break ??
     run -X

   Grab the .gdbinit from the PHP source tree and have a look at the macros.

5. The basics of APCu

   APCu has three main component parts:
		1) shared memory allocator
		2) pooling
		3) a safe, fast, implementation of a userland cache
	
5.1) APCu SMA
   
   It is a pretty standard memory allocator, now supporting third party extensions.

   apc_sma_malloc, apc_sma_realloc, apc_sma_strdup and apc_sma_free 
   behave to the caller just like malloc, realloc, strdup and free, they are 
   generated from macros in apc_sma_api.h

	Note:   apc_sma_api.h is formatted and designed such that the SMA APCu 
			uses can be used by third parties in their own extensions without
			interfering with, or consuming the resources of APCu itself

	apc_sma is a structure of type apc_sma_t, it is statically allocated at runtime,
	appropriate handlers are generated and set, and the structure made ready for initialization.

    MINIT then initializes apc_sma with apc_sma_api_init(&apc_sma). APCu SMA then takes 
    care of mmaping the shared memory for use by everyone with a reference to apc_sma. 
    ( which you can obtain in any compilation unit with apc_sma_api_extern(apc_sma) )  
	
	At this point, we have a completely useless 32MB chunk of memory at our disposal, before
	it can be used, an apc_cache_header_t is initialized at the beginning of the reigon of
	mmapp'ed memory.
    
    The header serves as a place to store, among other things, statistical information and a lock.
    
    Immediately after the header comes a zero sized block, immediately after that a single
	block the remaining size of the shared memory.

    At this point, the shared memory looks like this:

     +--------+--------+----------------------------------+
     | header | 0-size |              shared              |
     +--------+--------+----------------------------------+

   The blocks are just a simple offset-based linked list (so no pointers):

     typedef struct block_t block_t;
     struct block_t {
         size_t size;       /* size of this block */
         size_t next;       /* offset in segment of next free block */
         size_t canary;     /* canary to check for memory overwrites */
#ifdef __APC_SMA_DEBUG__
         int id;         /* identifier for the memory block */
#endif
     };

   The BLOCKAT macro turns an offset into an actual address for you:

     #define BLOCKAT(offset) ((block_t*)((char *)shmaddr + offset))

   where shmaddr = sma->shaddrs[0]

   And the OFFSET macro goes the other way:

     #define OFFSET(block) ((int)(((char*)block) - (char*)shmaddr))

   Allocating a block walks through the linked list of blocks until it finds one that is >= 
   to the requested size. The first call to allocate will hit the second block.  We then
   chop up that block so it looks like this:

     +--------+-------+-------+-------------------------+
     | header | block | block |         block           |
     +--------+-------+-------+-------------------------+

   Then we unlink that block from the linked list so it won't show up
   as an available block on the next allocate.  So we actually have:

     +--------+-------+       +-------------------------+
     | header | block |------>|         block           |
     +--------+-------+       +-------------------------+

   And header->avail along with block->size of the remaining large
   block are updated accordingly.  The arrow there representing the
   link which now points to a block with an offset further along in
   the segment.

   When the block is freed the steps are basically just reversed.  
   The block is put back and then the deallocate code looks at the block before and after to see 
   if the block immediately before and after are free and if so the blocks are combined.  So you never
   have 2 free blocks next to each other, apart from at the front with that
   0-sized dummy block.  This mostly prevents fragmentation.  I have been
   toying with the idea of always allocating block at 2^n boundaries to make
   it more likely that they will be re-used to cut down on fragmentation further.
   That's what the POWER_OF_TWO_BLOCKSIZE you see in apc_sma.c is all about.
  
5.2) APCu Pooling

   Pooling serves as a means to provide operations with a context: without context, managing memory within
   APCu would become near impossible, and very error prone.

   Whenever APCu is instructed to undertake an operation that requires relinquishing the owner of some memory
   a struct of type apc_cache_context_t is passed, among other things, the context contains a pool,
   the pool provides references to handlers that are appropriate for the current operation.

   For example: To copy data into the shared area, APCu will require the use of allocators that return blocks
				from shared memory. To copy data out of the shared area and hand over ownership to PHP, normal
				allocators must be used.

   For more information about pooling, see apc_pool.h/apc_pool.c in the source distribution.

5.3) APCu Cache

   The caching functionality of APCu is provided by a modified version of the APC source code

   APC used cache level locking to ensure integrity of data - any time you wrote into or read from the cache
   you acquired and released a global cache lock: This somewhat hinders performance, at least in theory, it complicates
   implementation of new features and ideas, and raises the barrier rather high for maintainers.

   APCu adopts a different method of ensuring integrity by moving the locking to the slot level.
   APCu pays close attention to the problems inherent in a system being executed in an environment where concurrency is certain.
   
   When headers are manipulated ( any part ), the operations are done so with the protection of a mutex, such short, efficient operations
   are not a candidate for enough contention for concern. When the counter or state flag is set, the mutex is released immediately, no lock is
   held at the cache level while APCu manipulates data. 

   This means that almost all of the API that needs to be maintained is completely free from locking.
   
   In addition to simplified and advanced locking, some simple tweaks have been applied. 
     The possibility to control more finely what happens when resources become low for APCu.
     A unified, general purpose implementation of a read/write lock, used everywhere, by everything.
     Simplified configuration of APCu will ensure good performance out of the box
     Agressive commenting of every source file I have changed or organized, the beginnings of a well documented APC !!

   There's probably some of my blood in it, if you look real close ...

   The remainder of the document goes on to explain in some detail the cache itself, which is almost unchanged in APCu

6. Next up is apc_cache.c which implements the cache logic.

   A cache consists of a block of shared memory returned by apc_sma_allocate() via apc_sma_malloc().  
   You will notice references to apc_emalloc().  apc_emalloc() is just a thin wrapper
   around system allocators (malloc etc).  Don't confuse apc_emalloc() and 
   apc_sma_malloc() as only the latter returns blocks from shared memory.

   The cache is stored in/described by this struct allocated locally using apc_emalloc():

     struct apc_cache_t {
         void* shmaddr;              /* process (local) address of shared cache */
         apc_cache_header_t* header; /* cache header (stored in SHM) */
         apc_cache_slot_t** slots;   /* array of cache slots (stored in SHM) */
         int num_slots;              /* number of slots in cache */
         int gc_ttl;                 /* maximum time on GC list for a slot */
         int ttl;                    /* if slot is needed and entry's access time is older than this ttl, remove it */
         long smart;                 /* determine how to expunge the cache */
     };

   Whenever you see functions that take a 'cache' argument, this is what they
   take.  And apc_cache_create() returns a pointer to this populated struct.

   At the beginning of the cache we have a header.  Remember, we are down a level now
   from the sma stuff.  The sma stuff is the low-level shared-memory allocator which
   has its own header which is completely separate and invisible to apc_cache.c.  
   As far as apc_cache.c is concerned the block of memory it is working with could 
   have come from a call to malloc().

   The header looks like this:

     typedef struct apc_cache_header_t apc_cache_header_t;
     struct apc_cache_header_t {
		apc_lock_t lock;                      /* header lock */
		unsigned long num_hits;               /* total successful hits in cache */
		unsigned long num_misses;             /* total unsuccessful hits in cache */
		unsigned long num_inserts;            /* total successful inserts in cache */
		unsigned long expunges;               /* total number of expunges */
		apc_cache_slot_t* deleted_list;       /* linked list of to-be-deleted slots */
		time_t start_time;                    /* time the above counters were reset */
		zend_bool busy;                       /* Flag to tell clients when we are busy cleaning the cache */
		int num_entries;                      /* Statistic on the number of entries */
		size_t mem_size;                      /* Statistic on the memory size used by this cache */
		long smart;                           /* adjustable smart expunges of data */
		apc_cache_key_l lastkey;              /* information about the last key inserted */
     };

   Since this is at the start of the shared memory segment, these values are accessible
   across all processes / threads and hence access to them has to be locked.

   After the header we have an array of slots.  The number of slots is user-defined
   through the apc.num_slots ini hint.  Each slot is described by:

     typedef struct apc_cache_slot_t apc_cache_slot_t;
     struct apc_cache_slot_t {
		apc_lock_t lock;            /* slot lock */
		apc_cache_key_t key;        /* slot key */
		apc_cache_entry_t* value;   /* slot value */
		apc_cache_slot_t* next;               /* next slot in linked list */
		unsigned long num_hits;     /* number of hits to this bucket */
		time_t creation_time;       /* time slot was initialized */
		time_t deletion_time;       /* time slot was removed from cache */
		time_t access_time;         /* time slot was last accessed */
     };

   The apc_cache_slot_t *next there is a linked list to other slots that happened to hash to the
   same array position.

   apc_cache_insert() shows what happens on a new cache insert.

     slot = &cache->slots[hash(key) % cache->num_slots];

   cache->slots is our array of slots in the segment.

   So, on an insert we find the array position in the slots array by hashing the key provided.
   If there are currently no other slots there, we just create the slot and stick it into
   the array:

     *slot = make_slot(key, value, *slot, t)

   If there are other slots already at this position we walk the link list to get to
   the end. Locking each slot as we move through the list.

   While walking the linked list we also check to see if the cache has a TTL defined.
   If while walking the linked list we see a slot that has expired, we remove it
   since we are right there looking at it.  This is the only place we remove stale
   entries unless the shared memory segment fills up and we force a full expunge via
   apc_cache_expunge().  apc_cache_expunge() walks all slots attempting deletion, how
   deletion occurs depends on runtime parameters, see INSTALL for runtime parameter
   configuration details.

   apc_cache_find() simply hashes and returns the entry if it is there.  If it is there
   but older than the mtime in the entry we are looking for, we delete the one that is
   there and return indicating we didn't find it.

   Next we need to understand what an actual cache entry looks like.  Have a look at
   apc_cache.h for the structs.  Here is an extract of apc_cache_key_t:

     typedef struct _apc_cache_key_t {
		const char *identifier;		  /* the identifier for this key */
		int identifier_len;			  /* the length of the identifier string */
		unsigned long h;              /* pre-computed hash value */
		time_t mtime;                 /* the mtime of this cached entry */
		apc_cache_owner_t owner;      /* the context that created this key */
     } apc_cache_key_t;   

   To create a apc_cache_key_t structure, call apc_cache_make_key(), see apc_cache.h
	
   Ok, on to the actual cache entry, here is an extract of apc_cache_entry_t:

     typedef struct _apc_cache_entry_t {
             zval *val;                    /* the zval copied at store time */
			unsigned int ttl;             /* the ttl on this specific entry */
			int ref_count;                /* the reference count of this entry */
			size_t mem_size;              /* memory used */
			apc_pool *pool;               /* pool which allocated the value */
     } apc_cache_entry_t;

   To create an apc_cache_entry_t, call apc_cache_make_entry(), see apc_cache.h

   Any of the structures taken by apc_cache_* functions have their equivalent apc_cache_make_*

   If an insertion of an entry should fail, it falls to the caller of insert to free 
   the pooled resources used to create the entry. 

If you made it to the end of this, you should have a pretty good idea of where things are in
the code.  There is much more reading to do in headers ... good luck ...

